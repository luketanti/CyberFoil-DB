name: Build US-EN Media DB

on:
  workflow_dispatch:

jobs:
  build-media-db:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Setup dependencies
        run: |
          sudo apt update
          sudo apt install -y libcurl4-openssl-dev libssl-dev
          python -m pip install --upgrade pip
          pip install requests pillow
          git clone https://github.com/blawar/nut
          cd nut
          pip install -r requirements.txt
          git clone --depth=1 https://github.com/blawar/titledb
          mkdir -p build_artefacts

      - name: Generate titles.US.en.json
        run: |
          cd nut
          python - <<'PY'
          import json
          import os
          import sys

          os.chdir(os.getcwd())
          sys.path.append(os.getcwd())
          import nut

          nut.importRegion("US", "en")
          os.rename("titledb/titles.json", "build_artefacts/titles.US.en.json")
          print("Generated build_artefacts/titles.US.en.json")
          PY

      - name: Build icon.db and banners.db
        run: |
          cd nut
          python - <<'PY'
          import hashlib
          import io
          import json
          import os
          import sqlite3
          from datetime import datetime, timezone

          import requests
          from PIL import Image, ImageOps
          from requests.adapters import HTTPAdapter
          from urllib3.util.retry import Retry

          TITLES_PATH = "build_artefacts/titles.US.en.json"
          ICON_DB_PATH = "build_artefacts/icon.db"
          BANNER_DB_PATH = "build_artefacts/banners.db"
          TARGET_SIZE = (128, 128)

          def now_iso():
              return datetime.now(timezone.utc).isoformat()

          def build_session():
              retry = Retry(
                  total=4,
                  read=4,
                  connect=4,
                  backoff_factor=0.5,
                  status_forcelist=(429, 500, 502, 503, 504),
                  allowed_methods=frozenset(["GET"]),
              )
              adapter = HTTPAdapter(max_retries=retry)
              s = requests.Session()
              s.mount("http://", adapter)
              s.mount("https://", adapter)
              s.headers.update({"User-Agent": "ownfoil-media-db-builder/1.0"})
              return s

          def init_db(path):
              if os.path.exists(path):
                  os.remove(path)
              conn = sqlite3.connect(path)
              conn.execute("PRAGMA journal_mode=OFF")
              conn.execute("PRAGMA synchronous=OFF")
              conn.execute(
                  """
                  CREATE TABLE images (
                      title_id TEXT PRIMARY KEY,
                      url TEXT NOT NULL,
                      format TEXT NOT NULL,
                      width INTEGER NOT NULL,
                      height INTEGER NOT NULL,
                      size_bytes INTEGER NOT NULL,
                      source_sha256 TEXT NOT NULL,
                      fetched_at TEXT NOT NULL,
                      image BLOB NOT NULL
                  )
                  """
              )
              conn.execute("CREATE INDEX idx_images_url ON images(url)")
              return conn

          def load_titles(path):
              with open(path, "r", encoding="utf-8") as f:
                  payload = json.load(f)
              if isinstance(payload, dict):
                  return payload
              return {}

          def collect_links(entries, key_name):
              out = {}
              for map_key, entry in entries.items():
                  if not isinstance(entry, dict):
                      continue
                  title_id = str(entry.get("id") or map_key or "").strip().upper()
                  if not title_id:
                      continue
                  url = str(entry.get(key_name) or "").strip()
                  if not url:
                      continue
                  out[title_id] = url
              return out

          def fetch_and_resize(session, url):
              resp = session.get(url, timeout=20)
              resp.raise_for_status()
              source_bytes = resp.content
              source_sha = hashlib.sha256(source_bytes).hexdigest()

              with Image.open(io.BytesIO(source_bytes)) as im:
                  im = ImageOps.exif_transpose(im)
                  if im.mode not in ("RGB", "RGBA"):
                      im = im.convert("RGB")
                  elif im.mode == "RGBA":
                      bg = Image.new("RGB", im.size, (255, 255, 255))
                      bg.paste(im, mask=im.split()[-1])
                      im = bg
                  fitted = ImageOps.fit(im, TARGET_SIZE, method=Image.Resampling.LANCZOS)

                  out = io.BytesIO()
                  fitted.save(out, format="WEBP", quality=80, method=6)
                  out_bytes = out.getvalue()
              return out_bytes, source_sha

          def populate_db(conn, items, label):
              session = build_session()
              ok = 0
              failed = 0
              bytes_total = 0
              cur = conn.cursor()
              for idx, (title_id, url) in enumerate(items.items(), start=1):
                  try:
                      webp_bytes, source_sha = fetch_and_resize(session, url)
                      cur.execute(
                          """
                          INSERT OR REPLACE INTO images
                          (title_id, url, format, width, height, size_bytes, source_sha256, fetched_at, image)
                          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                          """,
                          (
                              title_id,
                              url,
                              "webp",
                              TARGET_SIZE[0],
                              TARGET_SIZE[1],
                              len(webp_bytes),
                              source_sha,
                              now_iso(),
                              sqlite3.Binary(webp_bytes),
                          ),
                      )
                      ok += 1
                      bytes_total += len(webp_bytes)
                  except Exception as e:
                      failed += 1
                      print(f"[{label}] failed {idx}/{len(items)} {title_id}: {e}")
              conn.commit()
              print(f"[{label}] done ok={ok} failed={failed} bytes={bytes_total}")
              return ok, failed, bytes_total

          entries = load_titles(TITLES_PATH)
          icon_items = collect_links(entries, "iconUrl")
          banner_items = collect_links(entries, "bannerUrl")

          print(f"Found icon links: {len(icon_items)}")
          print(f"Found banner links: {len(banner_items)}")

          icon_conn = init_db(ICON_DB_PATH)
          banner_conn = init_db(BANNER_DB_PATH)
          try:
              populate_db(icon_conn, icon_items, "icon")
              populate_db(banner_conn, banner_items, "banner")
          finally:
              icon_conn.close()
              banner_conn.close()

          print(f"Wrote {ICON_DB_PATH}")
          print(f"Wrote {BANNER_DB_PATH}")
          PY

      - uses: actions/upload-artifact@v4
        with:
          name: icon.db
          path: nut/build_artefacts/icon.db
          compression-level: 9

      - uses: actions/upload-artifact@v4
        with:
          name: banners.db
          path: nut/build_artefacts/banners.db
          compression-level: 9
